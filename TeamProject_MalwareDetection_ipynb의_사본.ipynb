{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/park1NG/winterTIL/blob/main/TeamProject_MalwareDetection_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 드라이브 설정"
      ],
      "metadata": {
        "id": "Aale8Jxv8bhY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM_o_ZM66OcU"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/Shareddrives/BigDataSecurity'"
      ],
      "metadata": {
        "id": "YsYarYqG6S4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "HzfOCDO86Wxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모듈 불러오기"
      ],
      "metadata": {
        "id": "LlbI6roy8goa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, utils, datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils, datasets\n",
        "import torch.utils.data\n",
        "import os\n",
        "import time\n",
        "# 전처리\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import hog\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "ckUwJYuE6Zep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageFile\n",
        "from PIL import Image\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True # prevent truncate error"
      ],
      "metadata": {
        "id": "3LEOq0sGlUdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋 불러오기\n"
      ],
      "metadata": {
        "id": "UMfcc6IX8l-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_transforms = {\n",
        "    \"train\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),        \n",
        "    ]),\n",
        "    \"test\": transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "}"
      ],
      "metadata": {
        "id": "yE3cKQrFlhK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "malware_list = {'Adposhel': 0,\n",
        " 'Allaple.A': 0,\n",
        " 'Amonetize': 0,\n",
        " 'Autorun': 0,\n",
        " 'Benign Files': 1,\n",
        " 'BrowseFox': 0,\n",
        " 'Dinwod': 0,\n",
        " 'InstallCore': 0,\n",
        " 'MultiPlug': 0,\n",
        " 'VBA': 0,\n",
        " 'Vilsel': 0}"
      ],
      "metadata": {
        "id": "wlneD9fy4ivH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_transform(label):\n",
        "    # 예시: 클래스 레이블을 원하는 형태로 변환\n",
        "    if label != 4:\n",
        "      return 0\n",
        "    else:\n",
        "      return 1"
      ],
      "metadata": {
        "id": "Lax6SL6-4l11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil\n",
        "\n",
        "# train_folder = './Project/Train'\n",
        "# validation_folder = './Project/Validation'\n",
        "\n",
        "# ipynb_checkpoint_train = os.path.join(train_folder, '.ipynb_checkpoints')\n",
        "# ipynb_checkpoint_validation = os.path.join(validation_folder, '.ipynb_checkpoints')\n",
        "\n",
        "# if os.path.exists(ipynb_checkpoint_train):\n",
        "#     shutil.rmtree(ipynb_checkpoint_train)\n",
        "\n",
        "# if os.path.exists(ipynb_checkpoint_validation):\n",
        "#     shutil.rmtree(ipynb_checkpoint_validation)"
      ],
      "metadata": {
        "id": "0rSx79irmgGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets.ImageFolder(root = './Project/Train')"
      ],
      "metadata": {
        "id": "y40ZwosJlzy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.ImageFolder(root = './Project/Train', \n",
        "                                  transform = image_transforms['train'], target_transform = label_transform)\n",
        "\n",
        "test_data = datasets.ImageFolder(root = './Project/Validation', \n",
        "                                 transform = image_transforms['test'], target_transform = label_transform)"
      ],
      "metadata": {
        "id": "SfHDr1YE8r4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_size = int(0.5 * len(test_data))\n",
        "test_size = int(0.5 * len(test_data))\n",
        "\n",
        "valid_data, test_data = torch.utils.data.random_split(test_data, [val_size, test_size])"
      ],
      "metadata": {
        "id": "IbvHCg1jk2u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True) # make train loader\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=128, shuffle=False) # make test loader\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=False) # make test loader"
      ],
      "metadata": {
        "id": "jW1vepJ_mGQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "metadata": {
        "id": "cS7alUIxwkKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.class_to_idx  = malware_list # class name"
      ],
      "metadata": {
        "id": "mRfacWXn5Jbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = train_data.class_to_idx\n",
        "classes"
      ],
      "metadata": {
        "id": "_H9c_LG_6WKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "# print(dataiter.next())\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print()\n",
        "\n",
        "labels = labels.tolist()\n",
        "print(' '.join(f'{list(classes.keys())[list(classes.values()).index(j)]}' for j in labels))"
      ],
      "metadata": {
        "id": "A5r9_7v1mCHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전처리"
      ],
      "metadata": {
        "id": "9kIZ0uDE8sfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enhanced_data = []  # List to store enhanced images\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "6wbls7ImxtCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Laplacian Filtering (Edge 강화)"
      ],
      "metadata": {
        "id": "1S7GMxby5rbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if len(enhanced_data) == 0:\n",
        "    # enhanced_data가 비어 있을 경우 train_loader를 사용하여 전처리\n",
        "    for data in train_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        enhanced_images = []\n",
        "        # 라플라시안 필터 적용\n",
        "        for image in images:\n",
        "            # 라플라시안 필터 적용\n",
        "            image = image.permute(1, 2, 0).cpu().numpy()  # PyTorch tensor를 NumPy 배열로 변환\n",
        "            image = cv2.resize(image, (224, 224))  # 이미지 크기 조정\n",
        "            edge = cv2.Laplacian(image, -1)\n",
        "            filtered_image = np.hstack((image, edge))\n",
        "            enhanced_images.append(filtered_image)\n",
        "        enhanced_images = np.array(enhanced_images)\n",
        "        enhanced_data.append((enhanced_images.squeeze(), labels))\n",
        "\n",
        "        # enhanced_data에 필터링된 이미지와 레이블을 추가합니다.\n",
        "        enhanced_data.extend([(enhanced_image.squeeze(), label) for enhanced_image, label in zip(enhanced_images, labels)])\n",
        "else:\n",
        "    # enhanced_data가 비어 있지 않을 경우 enhanced_loader를 사용하여 전처리\n",
        "    filtered_data = []  # 필터링된 데이터를 임시로 저장할 리스트를 생성합니다.\n",
        "    for data in enhanced_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        enhanced_images = []\n",
        "        # 라플라시안 필터 적용\n",
        "        for image in images:\n",
        "            # 라플라시안 필터 적용\n",
        "            image = image.permute(1, 2, 0).cpu().numpy()  # PyTorch tensor를 NumPy 배열로 변환\n",
        "            image = cv2.resize(image, (224, 224))  # 이미지 크기 조정\n",
        "            edge = cv2.Laplacian(image, -1)\n",
        "            filtered_image = np.hstack((image, edge))\n",
        "            enhanced_images.append(filtered_image)\n",
        "        enhanced_images = np.array(enhanced_images)\n",
        "        enhanced_data.append((enhanced_images.squeeze(), labels))\n",
        "\n",
        "        # enhanced_data에 필터링된 이미지와 레이블을 추가합니다.\n",
        "        enhanced_data.extend([(enhanced_image.squeeze(), label) for enhanced_image, label in zip(enhanced_images, labels)])\n"
      ],
      "metadata": {
        "id": "5aIy6BJ36U1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create enhanced DataLoader\n",
        "enhanced_loader = DataLoader(enhanced_data, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "ANrQ6dreNxDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Bilateral Filtering (노이즈 제거)"
      ],
      "metadata": {
        "id": "vW2VjeIPtFpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if len(enhanced_data) == 0:\n",
        "    # enhanced_data가 비어 있을 경우 train_loader를 사용하여 전처리\n",
        "    for data in train_loader:\n",
        "      images, labels = data[0].to(device), data[1].to(device)\n",
        "      enhanced_images = []\n",
        "      for image in images:\n",
        "            image = image.permute(1, 2, 0).cpu().numpy()  # PyTorch tensor를 NumPy 배열로 변환\n",
        "            image = cv2.resize(image, (24, 224))  # 이미지 크기 조정\n",
        "            filtered_image = cv2.bilateralFilter(image, -1, 10, 5)\n",
        "            enhanced_images.append(filtered_image)\n",
        "      enhanced_images = np.array(enhanced_images)\n",
        "      enhanced_data.append((filtered_image.squeeze(), labels))\n",
        "\n",
        "      # enhanced_data에 필터링된 이미지와 레이블을 추가합니다.\n",
        "      enhanced_data.extend([(enhanced_image.squeeze(), label) for enhanced_image, label in zip(enhanced_images, labels)])\n",
        "else:\n",
        "     # enhanced_data가 비어 있지 않을 경우 enhanced_loader를 사용하여 전처리\n",
        "    filtered_data = []  # 필터링된 데이터를 임시로 저장할 리스트를 생성합니다.\n",
        "    for data in enhanced_loader:\n",
        "      images, labels = data[0].to(device), data[1].to(device)\n",
        "      enhanced_images = []\n",
        "      for image in images:\n",
        "            image = image.permute(1, 2, 0).cpu().numpy()  # PyTorch tensor를 NumPy 배열로 변환\n",
        "            image = cv2.resize(image, (224, 224))  # 이미지 크기 조정\n",
        "            filtered_image = cv2.bilateralFilter(image, -1, 10, 5)\n",
        "            enhanced_images.append(filtered_image)\n",
        "      enhanced_images = np.array(enhanced_images)\n",
        "      enhanced_data.append((enhanced_images.squeeze(), labels))\n",
        "\n",
        "      # enhanced_data에 필터링된 이미지와 레이블을 추가합니다.\n",
        "      enhanced_data.extend([(enhanced_image.squeeze(), label) for enhanced_image, label in zip(enhanced_images, labels)])"
      ],
      "metadata": {
        "id": "k0e0qDf5zUjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create enhanced DataLoader\n",
        "enhanced_loader = DataLoader(enhanced_data, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "2mz8s_Y4NviF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Contrast 조정 ( CLAHE )"
      ],
      "metadata": {
        "id": "wXmJeqU6WZTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if len(enhanced_data) == 0:\n",
        "    # enhanced_data가 비어 있을 경우 train_loader를 사용하여 전처리\n",
        "    for data in train_loader:\n",
        "      images, labels = data[0].to(device), data[1].to(device)\n",
        "      enhanced_images = []\n",
        "      for image in images:\n",
        "            image = image.permute(1, 2, 0).cpu().numpy()  # PyTorch tensor를 NumPy 배열로 변환\n",
        "            image = cv2.resize(image, (224, 224))  # 이미지 크기 조정\n",
        "            clahe = cv2.createCLAHE(clipLimit=0.02, tileGridSize=(4,4))\n",
        "            filtered_images = clahe.apply(image)\n",
        "            enhanced_images.append(filtered_image)\n",
        "      enhanced_images = np.array(enhanced_images)\n",
        "      enhanced_data.append((enhanced_images.squeeze(), labels))\n",
        "\n",
        "      # enhanced_data에 필터링된 이미지와 레이블을 추가합니다.\n",
        "      enhanced_data.extend([(enhanced_image.squeeze(), label) for enhanced_image, label in zip(enhanced_images, labels)])\n",
        "else:\n",
        "     # enhanced_data가 비어 있지 않을 경우 enhanced_loader를 사용하여 전처리\n",
        "    filtered_data = []  # 필터링된 데이터를 임시로 저장할 리스트를 생성합니다.\n",
        "    for data in enhanced_loader:\n",
        "      images, labels = data[0].to(device), data[1].to(device)\n",
        "      enhanced_images = []\n",
        "      for image in images:\n",
        "            image = image.permute(1, 2, 0).cpu().numpy()  # PyTorch tensor를 NumPy 배열로 변환\n",
        "            image = cv2.resize(image, (224, 224))  # 이미지 크기 조정\n",
        "            image = image.astype(np.float32)  # 데이터 타입을 float32로 변환\n",
        "            clahe = cv2.createCLAHE(clipLimit=0.02, tileGridSize=(4,4))\n",
        "            filtered_images = clahe.apply(image)\n",
        "            enhanced_images.append(filtered_image)\n",
        "      enhanced_images = np.array(enhanced_images)\n",
        "      enhanced_data.append((enhanced_images.squeeze(), labels))\n",
        "\n",
        "      # enhanced_data에 필터링된 이미지와 레이블을 추가합니다.\n",
        "      enhanced_data.extend([(enhanced_image.squeeze(), label) for enhanced_image, label in zip(enhanced_images, labels)])"
      ],
      "metadata": {
        "id": "pWJ1zwuPY-aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create enhanced DataLoader\n",
        "enhanced_loader = DataLoader(enhanced_data, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "j77sGE3nNunq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  영상 압축( Wavelet Transform )"
      ],
      "metadata": {
        "id": "itn7qnyHWmYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pywt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Wavelet transform\n",
        "wavelet = 'db5'  # Daubechies family\n",
        "level = 2  # Number of decomposition levels\n",
        "coeffs = pywt.wavedec2(image, wavelet, level=level)\n",
        "\n",
        "# 재구성\n",
        "reconstructed_image = pywt.waverec2(coeffs, wavelet)"
      ],
      "metadata": {
        "id": "y_TreQjCWshX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(enhanced_data) == 0:\n",
        "    # enhanced_data가 비어 있을 경우 train_loader를 사용하여 전처리\n",
        "    for data in train_loader:\n",
        "      images, labels = data[0].to(device), data[1].to(device)\n",
        "      enhanced_images = []\n",
        "      for image in images:\n",
        "            image = image.permute(1, 2, 0).cpu().numpy()  # PyTorch tensor를 NumPy 배열로 변환\n",
        "            image = cv2.resize(image, (224, 224))  # 이미지 크기 조정\n",
        "            coeffs = pywt.wavedec2(image, wavelet, level=level)\n",
        "            filtered_image = pywt.waverec2(coeffs, wavelet)\n",
        "            enhanced_images.append(filtered_image)\n",
        "      enhanced_images = np.array(enhanced_images)\n",
        "      enhanced_data.append((filtered_image.squeeze(), labels))\n",
        "\n",
        "      # enhanced_data에 필터링된 이미지와 레이블을 추가합니다.\n",
        "      enhanced_data.extend([(enhanced_image.squeeze(), label) for enhanced_image, label in zip(enhanced_images, labels)])\n",
        "else:\n",
        "     # enhanced_data가 비어 있지 않을 경우 enhanced_loader를 사용하여 전처리\n",
        "    filtered_data = []  # 필터링된 데이터를 임시로 저장할 리스트를 생성합니다.\n",
        "    for data in enhanced_loader:\n",
        "      images, labels = data[0].to(device), data[1].to(device)\n",
        "      enhanced_images = []\n",
        "      for image in images:\n",
        "            image = image.permute(1, 2, 0).cpu().numpy()  # PyTorch tensor를 NumPy 배열로 변환\n",
        "            image = cv2.resize(image, (224, 224))  # 이미지 크기 조정\n",
        "            coeffs = pywt.wavedec2(image, wavelet, level=level)\n",
        "            filtered_image = pywt.waverec2(coeffs, wavelet)\n",
        "            enhanced_images.append(filtered_image)\n",
        "      enhanced_images = np.array(enhanced_images)\n",
        "      enhanced_data.append((enhanced_images.squeeze(), labels))\n",
        "\n",
        "      # enhanced_data에 필터링된 이미지와 레이블을 추가합니다.\n",
        "      enhanced_data.extend([(enhanced_image.squeeze(), label) for enhanced_image, label in zip(enhanced_images, labels)])"
      ],
      "metadata": {
        "id": "E0QfMVN7eisj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create enhanced DataLoader\n",
        "enhanced_loader = DataLoader(enhanced_data, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "WpNlUulENq-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HOG"
      ],
      "metadata": {
        "id": "FWmDitISpg_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.feature import hog\n"
      ],
      "metadata": {
        "id": "JGGQUlrBFWVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_hog_features(dir):\n",
        "    features = []\n",
        "    for subdir in sorted(os.listdir(dir)):\n",
        "        subdir_path = os.path.join(dir, subdir)\n",
        "        if os.path.isdir(subdir_path):\n",
        "            print(\"Processing directory:\", subdir_path)\n",
        "            for i, filename in enumerate(sorted(os.listdir(subdir_path))):\n",
        "                img_path = os.path.join(subdir_path, filename)\n",
        "                img = cv2.imread(img_path,0)\n",
        "                features.append(hog(img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=False))\n",
        "    features.shape()\n",
        "    return np.array(features)"
      ],
      "metadata": {
        "id": "gYRanEalFcnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir = \"Train/\"\n",
        "#HOG_descriptors = load_hog_features(dir)\n",
        "\n",
        "HOG_descriptors.shape\n",
        "GIST_descriptors.shape"
      ],
      "metadata": {
        "id": "wNs8Tbpz6fXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###GIST"
      ],
      "metadata": {
        "id": "E_Dqm17NFFTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-image"
      ],
      "metadata": {
        "id": "g9fAU5z4qpff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.util import view_as_blocks"
      ],
      "metadata": {
        "id": "qr4x57TSr8tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gabor 필터 생성 함수\n",
        "def create_filters(scales, orientations):\n",
        "    filters = []\n",
        "    for scale in range(scales[0], scales[1] + 1):\n",
        "        for orientation in np.arange(0, np.pi, np.pi / orientations):\n",
        "            filt_real = cv2.getGaborKernel((scale, scale), 1, orientation, scale, 0, ktype=cv2.CV_32F)\n",
        "            filt_imag = cv2.getGaborKernel((scale, scale), 1, orientation, scale, 0.5 * np.pi, ktype=cv2.CV_32F)\n",
        "            filt = filt_real + filt_imag\n",
        "            filt /= 2.0 * np.pi * scale * scale\n",
        "            filters.append(filt)\n",
        "    return filters\n",
        "\n",
        "# GIST 디스크립터 계산 함수\n",
        "def gist_descriptor_single_channel(image, scales=(8, 8), orientations=8, blocks=(4, 4)):    # Gabor 필터 생성\n",
        "    filters = create_filters(scales, orientations)\n",
        "    \n",
        "    # 이미지 크기와 블록 크기 계산\n",
        "    height, width = image.shape[:2]\n",
        "    block_size = height // blocks[0], width // blocks[1]\n",
        "\n",
        "    padding_size = blocks[0] * block_size[0] - height, blocks[1] * block_size[1] - width\n",
        "    \n",
        "    # 이미지 패딩 (필요한 경우)\n",
        "    if padding_size != (0, 0):\n",
        "        image = cv2.copyMakeBorder(image, 0, padding_size[0], 0, padding_size[1], cv2.BORDER_CONSTANT, value=0)\n",
        "    \n",
        "    # 이미지를 블록으로 분할\n",
        "    block_shape = (block_size[0], block_size[1])\n",
        "    blocks = view_as_blocks(image, block_shape=(block_size[0], block_size[1])).reshape(-1, *block_size, order='F')\n",
        "    \n",
        "    # 각 블록의 GIST 특성 추출\n",
        "    features = []\n",
        "    for block in blocks:\n",
        "        feats = []\n",
        "        for scale in filters:\n",
        "            for filt in scale:\n",
        "                filtered = cv2.filter2D(block, cv2.CV_64F, filt)\n",
        "                feats.append(filtered.mean())\n",
        "        features.append(feats)\n",
        "    \n",
        "    # 전체 GIST 디스크립터로 결합\n",
        "    return np.concatenate(features)\n",
        "\n",
        "\n",
        "def gist_descriptor(image, scales=(8, 8), orientations=8, blocks=(4, 4)):\n",
        "    if len(image.shape) == 3:\n",
        "    # 각 채널에 대해 GIST 디스크립터 계산\n",
        "        descriptors = [gist_descriptor_single_channel(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), scales, orientations, blocks)]            # 전체 GIST 디스크립터로 결합\n",
        "        return np.concatenate(descriptors)\n",
        "    else:\n",
        "    # 단일 채널 이미지의 경우 GIST 디스크립터를 한 번만 계산\n",
        "        return gist_descriptor_single_channel(image, scales, orientations, blocks)"
      ],
      "metadata": {
        "id": "K6l1xtUD8ysZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd "
      ],
      "metadata": {
        "id": "9SI1S6TDY9TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 악성코드 이미지 폴더에서 350개의 이미지에 대한 gist descriptor를 계산하여 반환\n",
        "def get_gist_descriptors(root_dir):\n",
        "    descriptors = []\n",
        "    for subdir in sorted(os.listdir(root_dir)):\n",
        "        subdir_path = os.path.join(root_dir, subdir)\n",
        "        if os.path.isdir(subdir_path):\n",
        "            print(\"Processing directory:\", subdir_path)\n",
        "            for i, filename in enumerate(os.listdir(subdir_path)):\n",
        "                # 파일 경로 생성\n",
        "                filepath = os.path.join(subdir_path, filename)\n",
        "                # 이미지 로드\n",
        "                image = cv2.imread(filepath)\n",
        "                # 이미지에 대한 GIST 디스크립터 계산\n",
        "                descriptor = gist_descriptor(image)\n",
        "                descriptors.append(descriptor)\n",
        "                \n",
        "                if i % 10 == 9:\n",
        "                    print(\"\\tProcessed\", i + 1, \"images\")\n",
        "    return np.array(descriptors)\n"
      ],
      "metadata": {
        "id": "6N9yeZsxb3kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = \"Train/\"\n",
        "# 각 폴더에서 350개의 이미지에 대한 gist descriptor 계산\n",
        "descriptors = get_gist_descriptors(root_dir)\n",
        "print(len(descriptors))\n",
        "print('GIST Descriptor Shape:', descriptors.shape)"
      ],
      "metadata": {
        "id": "SmteEYnvdI2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GIST_descriptors = descriptors"
      ],
      "metadata": {
        "id": "mqiMDLZunByT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SIFT"
      ],
      "metadata": {
        "id": "LPbFf12KjLrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sift_features = []"
      ],
      "metadata": {
        "id": "XAQZhRN-CD-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sift= cv2.xfeatures2d.SIFT_create()"
      ],
      "metadata": {
        "id": "T9cnUIx2ByJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "if len(enhanced_data) == 0:\n",
        "    # enhanced_data가 비어 있을 경우 train_loader를 사용하여 전처리\n",
        "    for data in train_loader:\n",
        "        features = []\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        for image, label in zip(images, labels):\n",
        "            image_np = image.permute(1, 2, 0).cpu().numpy()  # PyTorch tensor를 NumPy 배열로 변환\n",
        "            gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)  # RGB 이미지를 그레이스케일 이미지로 변환\n",
        "            gray = gray.astype(np.uint8)  # 데이터 타입을 np.uint8로 변환\n",
        "            kp, des = sift.detectAndCompute(gray, None)\n",
        "            if des is None:\n",
        "                continue  # SIFT 특징을 검출하지 못한 경우 다음 이미지로 넘어감\n",
        "            sift_feature = des\n",
        "            features.append((sift_feature.squeeze(), label))\n",
        "        features = np.array(features)\n",
        "        sift_features.append((features.squeeze(), labels))\n",
        "\n",
        "        sift_features.extend([(sift_feature.squeeze(), label) for sift_feature, label in zip(features, labels)])\n",
        "else:\n",
        "    # enhanced_data가 비어 있지 않을 경우 enhanced_loader를 사용하여 전처리\n",
        "    for data in enhanced_loader:\n",
        "        features = []\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        for image, label in zip(images, labels):\n",
        "            image_np = image.permute(1, 2, 0).cpu().numpy()  # PyTorch tensor를 NumPy 배열로 변환\n",
        "            gray = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)  # RGB 이미지를 그레이스케일 이미지로 변환\n",
        "            gray = gray.astype(np.uint8)  # 데이터 타입을 np.uint8로 변환\n",
        "            kp, des = sift.detectAndCompute(gray, None)\n",
        "            if des is None:\n",
        "                continue  # SIFT 특징을 검출하지 못한 경우 다음 이미지로 넘어감\n",
        "            sift_feature = des\n",
        "            features.append((sift_feature.squeeze(), label))\n",
        "        features = np.array(features)\n",
        "        sift_features.append((features.squeeze(), labels))\n",
        "\n",
        "        # enhanced_data에 필터링된 이미지와 레이블을 추가합니다.\n",
        "        sift_features.extend([(sift_feature.squeeze(), label) for sift_feature, label in zip(features, labels)])\n"
      ],
      "metadata": {
        "id": "rH3EIB-oBsAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PMnERWFy6V0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##EDA"
      ],
      "metadata": {
        "id": "Nm3SIBpBqxeJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 불러오기"
      ],
      "metadata": {
        "id": "gD8-uypZr5RU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE # sklearn 사용하면 easy !! \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "UvC0K5rwkMGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "시각화에 사용할 모델 불러오기"
      ],
      "metadata": {
        "id": "N0PkaiN0kT07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "model = torchvision.models.resnet18(pretrained=False)\n",
        "num_ftrs = model.fc.in_features # fc의 입력 노드 수를 산출한다. 512개\n",
        "model.fc = nn.Linear(num_ftrs, 10) # fc를 nn.Linear(num_ftrs, 10)로 대체, CIFAR10,,\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "ljlf-MYokPhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classifier 들어가기 직전에 값을 뽑아낼 것임\n",
        "# (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
        "print(model)"
      ],
      "metadata": {
        "id": "GnMOmvJkkSsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###T-SNE"
      ],
      "metadata": {
        "id": "V4SVucEQE6Us"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본 데이터 T-SNE"
      ],
      "metadata": {
        "id": "5TFLcCCID9u7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actual = []\n",
        "deep_features = []\n",
        "\n",
        "# Define a color map for each class\n",
        "color_map = plt.cm.get_cmap('tab10', len(malware_list))\n",
        "\n",
        "model.eval() # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        features = model(images)\n",
        "\n",
        "        deep_features += features.cpu().numpy().tolist()\n",
        "        actual += labels.cpu().numpy().tolist()"
      ],
      "metadata": {
        "id": "dGneXg6ulBLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tsne = TSNE(n_components=2, random_state=0)\n",
        "cluster = np.array(tsne.fit_transform(np.array(deep_features)))\n",
        "actual = np.array(actual)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for label, malware_type in malware_list.items():\n",
        "    idx = np.where(actual == malware_type)\n",
        "    plt.scatter(cluster[idx, 0], cluster[idx, 1], marker='.', label=label, color=color_map(i))\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w-rGnrc86IrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리한 데이터 T-SNE"
      ],
      "metadata": {
        "id": "XPHPJWeUEDDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actual = []\n",
        "deep_features = []\n",
        "\n",
        "model.eval() # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    for data in enhanced_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        features = model(images)\n",
        "\n",
        "        deep_features += features.cpu().numpy().tolist()\n",
        "        actual += labels.cpu().numpy().tolist()\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=0)\n",
        "cluster = np.array(tsne.fit_transform(np.array(deep_features)))\n",
        "actual = np.array(actual)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for label, malware_type in malware_list.items():\n",
        "    idx = np.where(actual == malware_type)\n",
        "    plt.scatter(cluster[idx, 0], cluster[idx, 1], marker='.', label=label)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-NtsAJt8EIJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIFT Feature T-SNE"
      ],
      "metadata": {
        "id": "G7CQ_YVREocT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and labels\n",
        "features = np.array([f[0] for f in sift_features])\n",
        "labels = np.array([f[1] for f in sift_features])\n",
        "\n",
        "# T-SNE를 사용하여 features를 2차원으로 축소합니다.\n",
        "tsne = TSNE(n_components=2, random_state=0, perplexity=5)\n",
        "cluster = np.array(tsne.fit_transform(features))\n",
        "\n",
        "# 시각화를 위해 산점도를 그립니다.\n",
        "plt.figure(figsize=(10, 10))\n",
        "for label, malware_type in malware_list.items():\n",
        "    idx = np.where(labels == malware_type)\n",
        "    plt.scatter(cluster[idx, 0], cluster[idx, 1], marker='.', label=label)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6QhuIbklEoD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UMAP"
      ],
      "metadata": {
        "id": "xtfhskOyifzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본 데이터 UMAP"
      ],
      "metadata": {
        "id": "fNzygx7QFAJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actual = []\n",
        "deep_features = []\n",
        "\n",
        "model.eval() # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    for data in train_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        features = model(images)\n",
        "\n",
        "        deep_features += features.cpu().numpy().tolist()\n",
        "        actual += labels.cpu().numpy().tolist()\n",
        "\n",
        "umap_emb = umap.UMAP(n_components=2, random_state=0)\n",
        "embedded = umap_emb.fit_transform(np.array(deep_features))\n",
        "actual = np.array(actual)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for label, malware_type in malware_list.items():\n",
        "    idx = np.where(actual == malware_type)\n",
        "    plt.scatter(embedded[idx, 0], embedded[idx, 1], marker='.', label=label)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WvcfPIXdqGqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리한 데이터 UMAP"
      ],
      "metadata": {
        "id": "YirBSlFVFHyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "actual = []\n",
        "deep_features = []\n",
        "\n",
        "model.eval() # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    for data in enhanced_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        features = model(images)\n",
        "\n",
        "        deep_features += features.cpu().numpy().tolist()\n",
        "        actual += labels.cpu().numpy().tolist()\n",
        "\n",
        "umap_emb = umap.UMAP(n_components=2, random_state=0)\n",
        "embedded = umap_emb.fit_transform(np.array(deep_features))\n",
        "actual = np.array(actual)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for label, malware_type in malware_list.items():\n",
        "    idx = np.where(actual == malware_type)\n",
        "    plt.scatter(embedded[idx, 0], embedded[idx, 1], marker='.', label=label)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "afcm7u7BFHEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIFT UMAP"
      ],
      "metadata": {
        "id": "VrexbOE-GSGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sift_features = np.array(sift_features)  # sift_features를 numpy 배열로 변환\n",
        "\n",
        "# UMAP을 사용하여 차원 축소\n",
        "reducer = umap.UMAP(n_components=2)\n",
        "embedding = reducer.fit_transform(sift_features)\n",
        "\n",
        "# 시각화\n",
        "plt.figure(figsize=(10, 10))\n",
        "for label, malware_type in malware_list.items():\n",
        "    idx = np.where(actual == malware_type)\n",
        "    plt.scatter(embedding[idx, 0], embedding[idx, 1], marker='.', label=label)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tD9KXJkWGWLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 구성"
      ],
      "metadata": {
        "id": "XMOtVX1T8zu8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine Learning"
      ],
      "metadata": {
        "id": "e0yB7kJWG9oC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "with GIST"
      ],
      "metadata": {
        "id": "sKlhHbHPCK_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from xgboost import XGBClassifier\n"
      ],
      "metadata": {
        "id": "127llhZJ86o3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 데이터와 레이블 설정\n",
        "X = descriptors\n",
        "\n",
        "# 레이블 기록\n",
        "labels_dict = classes\n",
        "train_dir = \"Train/\"  # 이 경로에 train 데이터가 저장\n",
        "val_dir = \"Validation/\"  # 이 경로에 test 데이터가 저장\n",
        "\n",
        "# GIST_descriptors 및 레이블 불러오기\n",
        "X_train = X\n",
        "X_test = get_gist_descriptors(val_dir)\n",
        "\n",
        "# 레이블 설정\n",
        "labels_dict = classes\n",
        "\n",
        "# 각 이미지에 맞는 레이블 생성\n",
        "def load_labels(dir):\n",
        "    y = []\n",
        "    for subdir in sorted(os.listdir(dir)):\n",
        "        subdir_path = os.path.join(dir, subdir)\n",
        "        if os.path.isdir(subdir_path):\n",
        "            for i, filename in enumerate(sorted(os.listdir(subdir_path))):\n",
        "                y.append(labels_dict[subdir])\n",
        "    return np.array(y)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 모델 정의\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'XGBoost': XGBClassifier(),\n",
        "    'Linear SVM': LinearSVC(),\n",
        "    'SMO': SVC(kernel='rbf'), # SMO는 일반적으로 서포트 벡터 머신 (SVM)이 rbf 커널을 사용\n",
        "    'J48': DecisionTreeClassifier() # J48는 scikit-learn에서 Decision Tree에 해당\n",
        "}\n",
        "\n",
        "# 성능 지표\n",
        "scores = {'accuracy': accuracy_score, 'FPR': confusion_matrix, 'precision': precision_score, 'recall': recall_score, 'f1score': f1_score}\n",
        "\n",
        "# 각 모델에 대해 교차 검증 및 테스트 세트에서 성능 평가\n",
        "for model_name, model_instance in models.items():\n",
        "    print(model_name)\n",
        "    model_instance.fit(X_train_scaled, y_train)\n",
        "    y_pred = model_instance.predict(X_test_scaled)\n",
        "    for score_name, score_func in scores.items():\n",
        "        if score_name == 'FPR':\n",
        "            cm = score_func(y_test, y_pred)\n",
        "            fp = cm.sum(axis=0) - np.diag(cm)\n",
        "            tn = cm.sum() - (cm.sum(axis=1) + fp)\n",
        "            fpr = np.mean(fp / (fp + tn))\n",
        "            print(score_name, fpr)\n",
        "        elif score_name == 'accuracy':\n",
        "            print(score_name, score_func(y_test, y_pred))\n",
        "        else:\n",
        "            print(score_name, score_func(y_test, y_pred, average='weighted'))\n"
      ],
      "metadata": {
        "id": "L9u08FHiohj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with GIST+HOG"
      ],
      "metadata": {
        "id": "77Tl8hzqCTji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hog_gist_concatenated = np.concatenate((HOG_descriptors, GIST_descriptors), axis=1)\n",
        "hog_gist_concatenated.shape"
      ],
      "metadata": {
        "id": "WcL5lJfkCWfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 데이터와 레이블 설정\n",
        "X = hog_gist_concatenated\n",
        "\n",
        "# 레이블 기록\n",
        "labels_dict = classes\n",
        "train_dir = \"Train/\"  # 이 경로에 train 데이터가 저장\n",
        "val_dir = \"Validation/\"  # 이 경로에 test 데이터가 저장\n",
        "\n",
        "# GIST_descriptors 및 레이블 불러오기\n",
        "X_train = X\n",
        "X_test = get_gist_descriptors(val_dir)\n",
        "\n",
        "# 레이블 설정\n",
        "labels_dict = classes\n",
        "\n",
        "# 각 이미지에 맞는 레이블 생성\n",
        "def load_labels(dir):\n",
        "    y = []\n",
        "    for subdir in sorted(os.listdir(dir)):\n",
        "        subdir_path = os.path.join(dir, subdir)\n",
        "        if os.path.isdir(subdir_path):\n",
        "            for i, filename in enumerate(sorted(os.listdir(subdir_path))):\n",
        "                y.append(labels_dict[subdir])\n",
        "    return np.array(y)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Length of X:\", len(X))\n",
        "print(\"Length of y:\", len(y))\n",
        "\n",
        "# 모델 정의\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'XGBoost': XGBClassifier(),\n",
        "    'Linear SVM': LinearSVC(),\n",
        "    'SMO': SVC(kernel='rbf'), # SMO는 일반적으로 서포트 벡터 머신 (SVM)이 rbf 커널을 사용\n",
        "    'J48': DecisionTreeClassifier() # J48는 scikit-learn에서 Decision Tree에 해당\n",
        "}\n",
        "\n",
        "# 성능 지표\n",
        "scores = {'accuracy': accuracy_score, 'FPR': confusion_matrix, 'precision': precision_score, 'recall': recall_score, 'f1score': f1_score}\n",
        "\n",
        "# 각 모델에 대해 교차 검증 및 테스트 세트에서 성능 평가\n",
        "for model_name, model_instance in models.items():\n",
        "    print(model_name)\n",
        "    model_instance.fit(X_train_scaled, y_train)\n",
        "    y_pred = model_instance.predict(X_test_scaled)\n",
        "    for score_name, score_func in scores.items():\n",
        "        if score_name == 'FPR':\n",
        "            cm = score_func(y_test, y_pred)\n",
        "            fp = cm.sum(axis=0) - np.diag(cm)\n",
        "            tn = cm.sum() - (cm.sum(axis=1) + fp)\n",
        "            fpr = np.mean(fp / (fp + tn))\n",
        "            print(score_name, fpr)\n",
        "        elif score_name == 'accuracy':\n",
        "            print(score_name, score_func(y_test, y_pred))\n",
        "        else:\n",
        "            print(score_name, score_func(y_test, y_pred, average='weighted'))\n"
      ],
      "metadata": {
        "id": "8-hsPixdCwzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Learning"
      ],
      "metadata": {
        "id": "xBZt7eFTG_eR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model List"
      ],
      "metadata": {
        "id": "JLjcF_rC_l-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model-DNN"
      ],
      "metadata": {
        "id": "FQOpdoLX-L6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "imgG6JLnVqtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "하이퍼파라미터 설정"
      ],
      "metadata": {
        "id": "lCTtyRzMVsU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "patience = 5"
      ],
      "metadata": {
        "id": "mlH2raTSVuXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 정의"
      ],
      "metadata": {
        "id": "iV2yA2sLV2X7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        ############### Conv2d, MaxPool2d, Linear 함수에 들어갈 파라미터를 채우세요 ##############\n",
        "        self.conv1 = nn.Conv2d(3, 10, 3) # in_channel, out_channel, kernel size\n",
        "        self.pool = nn.MaxPool2d(3, 2) # kernel_size, stride\n",
        "        self.conv2 = nn.Conv2d(10, 20, 3)\n",
        "        self.fc1 = nn.Linear(56180, 160) # in_features, out_features\n",
        "        self.fc2 = nn.Linear(160, 120)\n",
        "        self.fc3 = nn.Linear(120, 26)\n",
        "        self.dropout1 = nn.Dropout(0.4)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "        ###########################################################################################\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = DNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Wd6NzrdyV5B8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, 3, 224, 224).to(device)\n",
        "output = model(x)\n",
        "print(output.size())\n",
        "\n",
        "summary(model, (3, 224, 224))"
      ],
      "metadata": {
        "id": "buNwVKqehRwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 및 평가 함수 정의"
      ],
      "metadata": {
        "id": "qXhKHCwCV62v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    for batch_x, batch_y in iterator:\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(batch_x)\n",
        "        loss = criterion(output, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        acc = (output.argmax(dim=1) == batch_y).float().mean()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "3Fhzu0R4V8dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in iterator:\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "\n",
        "            output = model(batch_x)\n",
        "            loss = criterion(output, batch_y)\n",
        "            acc = (output.argmax(dim=1) == batch_y).float().mean()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "tjFPcNp1V-VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Early Stopping 클래스 정의"
      ],
      "metadata": {
        "id": "4ssfZNY9WAEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience):\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.best_loss = float('inf')\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if val_loss > self.best_loss:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0"
      ],
      "metadata": {
        "id": "Xg4xvomdWBUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EarlyStopping 객체 생성\n",
        "num_epochs = 100\n",
        "early_stopping = EarlyStopping(patience=10)"
      ],
      "metadata": {
        "id": "ShJHe9-5WtuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습"
      ],
      "metadata": {
        "id": "rX8AmKX3WxXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_loader, criterion, device)\n",
        "\n",
        "    print(f\"Epoch: {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "    print(f\"Valid Loss: {valid_loss:.4f} | Valid Acc: {valid_acc:.4f}\")\n",
        "\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break"
      ],
      "metadata": {
        "id": "E4oVHUP1WxyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 평가"
      ],
      "metadata": {
        "id": "gZfRaX-NWHNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터로 최종 평가\n",
        "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "er6-guaRWIl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model-CNN basic"
      ],
      "metadata": {
        "id": "p_mc2Pzm-P2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        ############### Conv2d, MaxPool2d, Linear 함수에 들어갈 파라미터를 채우세요 ##############\n",
        "        self.conv1 = nn.Conv2d(3, 10, 3) # in_channel, out_channel, kernel size\n",
        "        self.pool = nn.MaxPool2d(3, 2) # kernel_size, stride\n",
        "        self.conv2 = nn.Conv2d(10, 20, 3)\n",
        "        self.fc1 = nn.Linear(56180, 160) # in_features, out_features\n",
        "        self.fc2 = nn.Linear(160, 120)\n",
        "        self.fc3 = nn.Linear(120, 26)\n",
        "        self.dropout1 = nn.Dropout(0.4)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "        ###########################################################################################\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "B1g9uChC-SSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # Use GPU if it's available # colab 런타임 유형 변경에서 GPU 선택할 것\n",
        "model = Net().to(device) # define the network"
      ],
      "metadata": {
        "id": "-sznHOjK-Vsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, 3, 224, 224).to(device)\n",
        "output = model(x)\n",
        "print(output.size())\n",
        "\n",
        "summary(model, (3, 224, 224))"
      ],
      "metadata": {
        "id": "Ebd7-pex-XvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model-ResNet50"
      ],
      "metadata": {
        "id": "DmnCSZA68p1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, config, output_dim):\n",
        "        super().__init__()\n",
        "                \n",
        "        block, n_blocks, channels = config\n",
        "        self.in_channels = channels[0]\n",
        "            \n",
        "        assert len(n_blocks) == len(channels) == 4\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "        \n",
        "        self.layer1 = self.get_model_layer(block, n_blocks[0], channels[0])\n",
        "        self.layer2 = self.get_model_layer(block, n_blocks[1], channels[1], stride = 2)\n",
        "        self.layer3 = self.get_model_layer(block, n_blocks[2], channels[2], stride = 2)\n",
        "        self.layer4 = self.get_model_layer(block, n_blocks[3], channels[3], stride = 2)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
        "        \n",
        "    def get_model_layer(self, block, n_blocks, channels, stride = 1):\n",
        "    \n",
        "        layers = []\n",
        "        \n",
        "        if self.in_channels != block.expansion * channels:\n",
        "            downsample = True\n",
        "        else:\n",
        "            downsample = False\n",
        "        \n",
        "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
        "        \n",
        "        for i in range(1, n_blocks):\n",
        "            layers.append(block(block.expansion * channels, channels))\n",
        "\n",
        "        self.in_channels = block.expansion * channels\n",
        "            \n",
        "        return nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.fc(h)\n",
        "        \n",
        "        return x, h"
      ],
      "metadata": {
        "id": "3GIVUYCI8ZHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    \n",
        "    expansion = 1\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, \n",
        "                               stride = stride, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
        "                               stride = 1, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        \n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
        "                             stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "        \n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        i = x\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        \n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "                        \n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "QRb75CaC8YpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "    \n",
        "    expansion = 4\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
        "        super().__init__()\n",
        "    \n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
        "                               stride = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
        "                               stride = stride, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(out_channels, self.expansion * out_channels, kernel_size = 1,\n",
        "                               stride = 1, bias = False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace = True)\n",
        "        \n",
        "        if downsample:\n",
        "            conv = nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size = 1, \n",
        "                             stride = stride, bias = False)\n",
        "            bn = nn.BatchNorm2d(self.expansion * out_channels)\n",
        "            downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            downsample = None\n",
        "            \n",
        "        self.downsample = downsample\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        i = x\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "                \n",
        "        if self.downsample is not None:\n",
        "            i = self.downsample(i)\n",
        "            \n",
        "        x += i\n",
        "        x = self.relu(x)\n",
        "    \n",
        "        return x"
      ],
      "metadata": {
        "id": "twSUre1m8YYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### model_info"
      ],
      "metadata": {
        "id": "7tQhxT6P8viD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple\n",
        "Model_Info = namedtuple('Model_Info', ['block', 'n_blocks', 'channels'])\n",
        "\n",
        "Model_config = Model_Info(block = Bottleneck,\n",
        "                               n_blocks = [3, 4, 6, 3],\n",
        "                               channels = [64, 128, 256, 512])"
      ],
      "metadata": {
        "id": "3SDkZ6Nb8xO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "pretrained_model = models.resnet50(pretrained = True)\n",
        "\n",
        "# Fine Tuning\n",
        "IN_FEATURES = pretrained_model.fc.in_features \n",
        "OUTPUT_DIM = 10\n",
        "\n",
        "fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)\n",
        "pretrained_model.fc = fc\n",
        "model = CustomModel(Model_config, OUTPUT_DIM)"
      ],
      "metadata": {
        "id": "4emuVAQs8ylG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Load\n",
        "model.load_state_dict(pretrained_model.state_dict())"
      ],
      "metadata": {
        "id": "cseDfD2K8zfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count trainable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "id": "-25g1f6h80Hf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LR_finder"
      ],
      "metadata": {
        "id": "5WjFwY-a80lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "START_LR = 1e-7\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=START_LR)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "3BD5cyC182aI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "from torchvision import models\n",
        "\n",
        "x = torch.randn(3, 3, 224, 224).to(device)\n",
        "output = model(x)\n",
        "\n",
        "summary(model, (3, 224, 224))"
      ],
      "metadata": {
        "id": "iTxkpY_A83OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "\n",
        "class LRFinder:\n",
        "    def __init__(self, model, optimizer, criterion, device):\n",
        "        \n",
        "        self.optimizer = optimizer\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.device = device\n",
        "        \n",
        "        torch.save(model.state_dict(), 'init_params.pt')\n",
        "\n",
        "    def range_test(self, iterator, end_lr = 10, num_iter = 100, \n",
        "                   smooth_f = 0.05, diverge_th = 5):\n",
        "        \n",
        "        lrs = []\n",
        "        losses = []\n",
        "        best_loss = float('inf')\n",
        "\n",
        "        lr_scheduler = ExponentialLR(self.optimizer, end_lr, num_iter)\n",
        "        \n",
        "        iterator = IteratorWrapper(iterator)\n",
        "        \n",
        "        for iteration in range(num_iter):\n",
        "\n",
        "            loss = self._train_batch(iterator)\n",
        "\n",
        "            #update lr\n",
        "            lr_scheduler.step()\n",
        "            \n",
        "            lrs.append(lr_scheduler.get_lr()[0])\n",
        "\n",
        "            if iteration > 0:\n",
        "                loss = smooth_f * loss + (1 - smooth_f) * losses[-1]\n",
        "                \n",
        "            if loss < best_loss:\n",
        "                best_loss = loss\n",
        "\n",
        "            losses.append(loss)\n",
        "            \n",
        "            if loss > diverge_th * best_loss:\n",
        "                print(\"Stopping early, the loss has diverged\")\n",
        "                break\n",
        "                       \n",
        "        #reset model to initial parameters\n",
        "        model.load_state_dict(torch.load('init_params.pt'))\n",
        "                    \n",
        "        return lrs, losses\n",
        "\n",
        "    def _train_batch(self, iterator):\n",
        "        \n",
        "        self.model.train()\n",
        "        \n",
        "        self.optimizer.zero_grad()\n",
        "        \n",
        "        x, y = iterator.get_batch()\n",
        "        \n",
        "        x = x.to(self.device)\n",
        "        y = y.to(self.device)\n",
        "        \n",
        "        y_pred, _ = self.model(x)\n",
        "                \n",
        "        loss = self.criterion(y_pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        self.optimizer.step()\n",
        "        \n",
        "        return loss.item()\n",
        "\n",
        "class ExponentialLR(_LRScheduler):\n",
        "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
        "        self.end_lr = end_lr\n",
        "        self.num_iter = num_iter\n",
        "        super(ExponentialLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        curr_iter = self.last_epoch + 1\n",
        "        r = curr_iter / self.num_iter\n",
        "        return [base_lr * (self.end_lr / base_lr) ** r for base_lr in self.base_lrs]\n",
        "\n",
        "class IteratorWrapper:\n",
        "    def __init__(self, iterator):\n",
        "        self.iterator = iterator\n",
        "        self._iterator = iter(iterator)\n",
        "\n",
        "    def __next__(self):\n",
        "        try:\n",
        "            inputs, labels = next(self._iterator)\n",
        "        except StopIteration:\n",
        "            self._iterator = iter(self.iterator)\n",
        "            inputs, labels, *_ = next(self._iterator)\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "    def get_batch(self):\n",
        "        return next(self)"
      ],
      "metadata": {
        "id": "zVpRNNGX848A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "END_LR = 10\n",
        "NUM_ITER = 30\n",
        "\n",
        "lr_finder = LRFinder(model, optimizer, criterion, device)\n",
        "lrs, losses = lr_finder.range_test(train_loader, END_LR, NUM_ITER)"
      ],
      "metadata": {
        "id": "gsyb7oK885n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_lr_finder(lrs, losses, skip_start = 10, skip_end = 30):\n",
        "    \n",
        "    if skip_end == 0:\n",
        "        lrs = lrs[skip_start:]\n",
        "        losses = losses[skip_start:]\n",
        "    else:\n",
        "        lrs = lrs[skip_start:-skip_end]\n",
        "        losses = losses[skip_start:-skip_end]\n",
        "    \n",
        "    fig = plt.figure(figsize = (16,8))\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    ax.plot(lrs, losses)\n",
        "    ax.set_xscale('log')\n",
        "    ax.set_xlabel('Learning rate')\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.grid(True, 'both', 'x')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "aGmKF75Q878P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FOUND_LR = 1e-3\n",
        "\n",
        "params = [\n",
        "          {'params': model.conv1.parameters(), 'lr': FOUND_LR / 10},\n",
        "          {'params': model.bn1.parameters(), 'lr': FOUND_LR / 10},\n",
        "          {'params': model.layer1.parameters(), 'lr': FOUND_LR / 8},\n",
        "          {'params': model.layer2.parameters(), 'lr': FOUND_LR / 6},\n",
        "          {'params': model.layer3.parameters(), 'lr': FOUND_LR / 4},\n",
        "          {'params': model.layer4.parameters(), 'lr': FOUND_LR / 2},\n",
        "          {'params': model.fc.parameters()}\n",
        "         ]\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(params, lr = FOUND_LR, weight_decay=0.0001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)"
      ],
      "metadata": {
        "id": "2oUFzEwX88sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='./net_pretrained.pth'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
        "                            Default: 7\n",
        "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
        "                            Default: False\n",
        "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
        "                            Default: 0\n",
        "            path (str): checkpoint저장 경로\n",
        "                            Default: './net_pretrained.pth'\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''validation loss가 감소하면 모델을 저장한다.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "TQauBjM58957"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "LmhpfKR387Zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_topk_accuracy(y_pred, y, k = 5):\n",
        "    with torch.no_grad():\n",
        "        batch_size = y.shape[0]\n",
        "        _, top_pred = y_pred.topk(k, 1)\n",
        "        top_pred = top_pred.t()\n",
        "        correct = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
        "        correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim = True)\n",
        "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim = True)\n",
        "        acc_1 = correct_1 / batch_size\n",
        "        acc_k = correct_k / batch_size\n",
        "    return acc_1, acc_k"
      ],
      "metadata": {
        "id": "vt_ASe_q87JF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc_1 = 0\n",
        "    epoch_acc_5 = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for (x, y) in iterator:\n",
        "        \n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        y_pred, _ = model(x)\n",
        "        \n",
        "        loss = criterion(y_pred, y)\n",
        "        \n",
        "        acc_1, acc_5 = calculate_topk_accuracy(y_pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc_1 += acc_1.item()\n",
        "        epoch_acc_5 += acc_5.item()\n",
        "        \n",
        "    epoch_loss /= len(iterator)\n",
        "    epoch_acc_1 /= len(iterator)\n",
        "    epoch_acc_5 /= len(iterator)\n",
        "        \n",
        "    return epoch_loss, epoch_acc_1, epoch_acc_5"
      ],
      "metadata": {
        "id": "qO-WJvKE9Aqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion, device):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc_1 = 0\n",
        "    epoch_acc_5 = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "\n",
        "        for (x, y) in iterator:\n",
        "\n",
        "           x = x.to(device)\n",
        "           y = y.to(device)\n",
        "\n",
        "           y_pred, _ = model(x)\n",
        "\n",
        "           loss = criterion(y_pred, y)\n",
        "\n",
        "           acc_1, acc_5 = calculate_topk_accuracy(y_pred, y)\n",
        "\n",
        "           epoch_loss += loss.item()\n",
        "           epoch_acc_1 += acc_1.item()\n",
        "           epoch_acc_5 += acc_5.item()\n",
        "\n",
        "          \n",
        "    epoch_loss /= len(iterator)\n",
        "    epoch_acc_1 /= len(iterator)\n",
        "    epoch_acc_5 /= len(iterator)\n",
        "        \n",
        "    return epoch_loss, epoch_acc_1, epoch_acc_5"
      ],
      "metadata": {
        "id": "yfFjUgwB9Cjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "metadata": {
        "id": "k6XPUIJz9DSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_valid_loss = float('inf')\n",
        "result_list = []\n",
        "lr_list = []\n",
        "\n",
        "patience = 5\n",
        "\n",
        "early_stopping = EarlyStopping(patience = patience, verbose = True)\n",
        "\n",
        "for epoch in range(100):\n",
        "    \n",
        "    start_time = time.monotonic()\n",
        "    \n",
        "    train_loss, train_acc_1, train_acc_5 = train(model, train_loader, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc_1, valid_acc_5 = evaluate(model, valid_loader, criterion, device)\n",
        "      \n",
        "    early_stopping(valid_loss, model)\n",
        "    lr_list.append(optimizer.param_groups[0][\"lr\"]) \n",
        "\n",
        "    # patience 동안 val_loss가 감소하지 않으면 조기 종료\n",
        "    if early_stopping.early_stop:\n",
        "      print(\"Early stopping\")\n",
        "      break\n",
        "\n",
        "    # val_loss 감소하면 best model 불러오기 \n",
        "    model.load_state_dict(torch.load('./net_pretrained.pth'))\n",
        "\n",
        "    end_time = time.monotonic()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc_1: {train_acc_1*100:6.2f}% | Train Acc_5: {train_acc_5*100:6.2f}%')\n",
        "    print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc_1: {valid_acc_1*100:6.2f}% | Train Acc_5: {train_acc_5*100:6.2f}%')\n",
        "\n",
        "    result = {\n",
        "    'EPOCH': epoch,\n",
        "    'Train Loss': train_loss,\n",
        "    'Train acc_1': train_acc_1,\n",
        "    'Train acc_5': train_acc_5,\n",
        "    'Valid Loss': valid_loss,\n",
        "    'Valid acc_1': valid_acc_1,\n",
        "    'Valid acc_5': valid_acc_5}\n",
        "  \n",
        "    result_list.append(result)\n",
        "  \n",
        "result_df = pd.DataFrame(result_list)"
      ],
      "metadata": {
        "id": "5ydfXopX9D3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 평가"
      ],
      "metadata": {
        "id": "18G7yplz89Xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss 및 Acc 변화 그래프\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
        "\n",
        "axes[0].plot(result_df['EPOCH'], result_df['Train Loss'], label='Train Loss')\n",
        "axes[0].plot(result_df['EPOCH'], result_df['Valid Loss'], label='Valid Loss')\n",
        "axes[0].legend()\n",
        "axes[0].set_title('Loss')\n",
        "\n",
        "axes[1].plot(result_df['EPOCH'], result_df['Train acc_1'], label='Train acc_1')\n",
        "axes[1].plot(result_df['EPOCH'], result_df['Valid acc_1'], label='Valid acc_1')\n",
        "axes[1].legend()\n",
        "axes[1].set_title('ACC_1')\n",
        "\n",
        "axes[2].plot(result_df['EPOCH'], result_df['Train acc_5'], label='Train acc_5')\n",
        "axes[2].plot(result_df['EPOCH'], result_df['Valid acc_5'], label='Valid acc_5')\n",
        "axes[2].legend()\n",
        "axes[2].set_title('ACC_5')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IhKgwzon9zG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lr_list)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Learning Rate\")"
      ],
      "metadata": {
        "id": "5JihiaQO-2Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('./net_pretrained.pth'))"
      ],
      "metadata": {
        "id": "cBcW3D2388_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc_1, test_acc_5 = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc @1: {test_acc_1*100:6.2f}% | Test Acc @5: {test_acc_5*100:6.2f}%')"
      ],
      "metadata": {
        "id": "YgCrh4cL9HUH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}